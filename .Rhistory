library(Giotto)
library(Seurat)
library(ggplot2)
library(patchwork)
options(bitmapType = 'cairo')
args <- commandArgs(trailingOnly = TRUE)
sample.name <- 151507
n_cluster <- 7
##### 1. Load Data
data_path = file.path('./data/DLPFC/', sample.name)
dir.output = file.path('./DLPFC_results/', sample.name)
if(!dir.exists(file.path(dir.output))){
dir.create(file.path(dir.output), recursive = TRUE)
}
expr_data_path=fs::path(data_path, "filtered_feature_bc_matrix.h5")
raw_matrix=get10Xmatrix_h5(path_to_data=expr_data_path)$`Gene Expression`
library(hdf5)
library(hdf5r)
raw_matrix=get10Xmatrix_h5(path_to_data=expr_data_path)$`Gene Expression`
install.packages("hdf5")
library(Giotto)
?get10Xmatrix_h5
library(devtools)
install_github("XiaoZhangryy/iSC.MEB")
library(BayesSpace)
library(Seurat)
library(Rcpp)
cppFunction('double EucC(NumericVector x , NumericVector y){
double sum = 0;
int size = x.size()
for (int i = 0 ; i < size ; i++){
sum = sum + pow(x[i] - y[i] , 2);
}
sum = sqrt(sum);
return sum;
}
')
library(Rcpp)
cppFunction('double EucC(NumericVector x, NumericVector y) {
double track = 0;
int n = x.size();
for(int i = 0; i < n; i++){
track = track + pow( (x[i] - y[i]), 2);
}
track = sqrt(track);
return track;
}
')
func <- function(vec)
{
n <- length(vec)
# for tracking sum and log
sum.log <- 0
log.of.vec <- numeric(length(n))
# calculating logs and sum for each element
for(i in 1:n)
{
log.of.vec[i] <- log(vec[i])
sum.log <- sum.log + log.of.vec[i]
}
# fraction
frac <- log.of.vec/sum.log
return(frac)
}
funcR <- function(vec){
temp <- log(vec);
return(temp / sum(temp))
}
cppFunction('NumericVector funcC(NumericVector x){
int sum = 0;
for(int i = 0 ; i < x.size() ; i++){
x[i] = log(x[i]);
sum = sum + x[i];
}
for(int j = 0 ; j < x.size() ; j++){
x[i] = x[i]/sum;
}
return x;
}
')
cppFunction('NumericVector funcC(NumericVector x){
int sum = 0;
for(int i = 0 ; i < x.size() ; i++){
x[i] = log(x[i]);
sum = sum + x[i];
}
for(int j = 0 ; j < x.size() ; j++){
x[j] = x[j]/sum;
}
return x;
}
')
all.equal(funcR(vec) , funcC(vec))
vec <- 1:10
all.equal(funcR(vec) , funcC(vec))
funcR(vec)
funcC(vec)
cppFunction('NumericVector funcC(NumericVector x){
int sum = 0;
NumericVector y = x;
for(int i = 0 ; i < x.size() ; i++){
y[i] = log(x[i]);
sum = sum + y[i];
}
for(int j = 0 ; j < x.size() ; j++){
y[j] = y[j]/sum;
}
return y;
}
')
vec <- 1:10
all.equal(funcR(vec) , funcC(vec))
cppFunction('NumericVector funcC(NumericVector x){
double sum = 0;
NumericVector y = x;
for(int i = 0 ; i < x.size() ; i++){
y[i] = log(x[i]);
sum = sum + y[i];
}
for(int j = 0 ; j < x.size() ; j++){
y[j] = y[j]/sum;
}
return y;
}
')
vec <- 1:10
all.equal(funcR(vec) , funcC(vec))
library(rbenchmark)
install.packages(rbenchmark)
install.packages("rbenchmark")
library(rbenchmark)
benchmark(func(vec) , funcR(vec) , funcC(vec))
vec <- 1:1e4
all.equal(funcR(vec) , funcC(vec))
benchmark(func(vec) , funcR(vec) , funcC(vec))
vec <- 1:1e6
all.equal(funcR(vec) , funcC(vec))
benchmark(func(vec) , funcR(vec) , funcC(vec))
library(SingleCellExperiment)
library(ggplot2)
library(BayesSpace)
for (i in c(151507:151510,151669:151676)){
if (i %in% c(151507:151510,151673:151676)){
q <- 7
} else {
q <- 5
}
i <- as.character(i)
dlpfc <- getRDS("2020_maynard_prefrontal-cortex", i)
set.seed(101)
dec <- scran::modelGeneVar(dlpfc)
top <- scran::getTopHVGs(dec, n = 2000)
set.seed(102)
dlpfc <- scater::runPCA(dlpfc, subset_row=top)
## Add BayesSpace metadata
dlpfc <- spatialPreprocess(dlpfc, platform="Visium", skip.PCA=TRUE)
# Number of clusters
d <- 15  # Number of PCs
## Run BayesSpace clustering
set.seed(104)
dlpfc <- spatialCluster(dlpfc, q=q, d=d, platform='Visium',
nrep=10000, gamma=3, save.chain=TRUE)
#saving results
path <- paste(i,".csv",sep = "")
path2 <- paste(i , ".jpeg" , sep = "")
write.csv(colData(dlpfc) , file = path)
plot <- clusterPlot(dlpfc, label=labels, palette=NULL, size=0.05) +
scale_fill_viridis_d(option = "A", labels = 1:7) +
labs(title="BayesSpace")
ggsave(filename = path2 , plot , device = "jpeg")
}
library(dplyr)
library(tidyverse)
library(RColorBrewer)
library(ggplot2)
air_quality <- read.csv("./Data_Air_Quality/air_quality.csv")
setwd("~/class-project-group-1")
library(dplyr)
library(tidyverse)
library(RColorBrewer)
library(ggplot2)
air_quality <- read.csv("./Data_Air_Quality/air_quality.csv")
air_qual <- as_tibble(air_quality)
air_qual$PM10_Annual_Average_g_m3 = as.numeric(air_qual$PM10_Annual_Average_g_m3)
#code for state_wise_pollution
air_qualf <- air_qual %>% group_by(State) %>% summarise(SO2_Annual_Average_g_m3 = mean(SO2_Annual_Average_g_m3) ,
NO2_Annual_Average_g_m3 = mean(NO2_Annual_Average_g_m3),
PM10_Annual_Average_g_m3 = mean(PM10_Annual_Average_g_m3 , na.rm = TRUE))
air_qualf <- as.data.frame(air_qualf)
air_qualf$State[6] = "Dadra and Nagar Haveli"
air_qualf$State[7] = "Daman and Diu"
air_qualf$State[13] = "Jammu and Kashmir"
air_qualf$State[22] = "Odisha"
air_qualf$State[26] = "Tamil Nadu"
air_qualf$State[5] = "Chhattisgarh"
PM25 <- read.csv("./Data_Respiratory_illnesses/PM25.csv")
air_qualf <- merge(air_qualf , PM25)
#code for quality_vs_ARI
Deaths_2011 <- read.csv("./Data_Respiratory_illnesses/Deaths_2011.csv")
ARI_and_factors <- read.csv("./Data_Respiratory_illnesses/State_wise_ARI_and_factors.csv")
ARI_and_factors <- ARI_and_factors[,-1]
Deaths_2011 <- Deaths_2011[,-1]
comp <- merge (air_qualf , Deaths_2011)
comp2 <- merge(air_qualf , ARI_and_factors)
#state max death/case
Deaths_2011[order(Deaths_2011$Total.Deaths.Cases , decreasing = TRUE),]
ordered_deaths <- Deaths_2011[order(Deaths_2011$Total.Deaths.Cases , decreasing = TRUE),]
ordered_deaths <- ordered_deaths[1:7,]
#state max death/case
Deaths_2011[order(Deaths_2011$Total.Deaths.Cases , decreasing = TRUE),]
ordered_deaths <- Deaths_2011[order(Deaths_2011$Total.Deaths.Cases , decreasing = FALSE),]
ordered_deaths <- ordered_deaths[1:7,]
# Create the barplot
ggplot(ordered_deaths, aes(x = State , y = Total.Deaths.Cases)) +
geom_bar(stat = "identity", fill = "purple") +
labs(title = paste("Barplot for states with highest deaths/cases")) +
xlab("States") +
ylab("Deaths/Cases")
ordered_deaths[,1:5]
